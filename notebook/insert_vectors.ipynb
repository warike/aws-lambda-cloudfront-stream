{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d9527bc3",
            "metadata": {},
            "source": [
                "# Insert Vectors into S3 Vector Index\n",
                "\n",
                "This notebook demonstrates how to insert predefined text into the S3 Vector Index by:\n",
                "1. Loading predefined text chunks.\n",
                "2. Generating embeddings for each chunk using the Titan v2 model.\n",
                "3. Creating metadata with unique IDs (similar to nanoid in JS) and raw text.\n",
                "4. Inserting vectors into the S3 Vector Index."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d34a4a4f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import boto3\n",
                "import os\n",
                "import json\n",
                "import secrets\n",
                "import string\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv(override=True)\n",
                "\n",
                "print(\"‚úÖ Libraries imported and environment variables loaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nanoid_function",
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_nanoid(size=21):\n",
                "    \"\"\"\n",
                "    Generate a unique ID similar to nanoid in JavaScript.\n",
                "    Uses URL-safe characters (A-Za-z0-9_-)\n",
                "    \"\"\"\n",
                "    alphabet = string.ascii_letters + string.digits + '_-'\n",
                "    return ''.join(secrets.choice(alphabet) for _ in range(size))\n",
                "\n",
                "# Test the function\n",
                "print(f\"Sample ID: {generate_nanoid()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "70666761",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "aws_region = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
                "aws_profile = os.getenv(\"AWS_PROFILE\", \"default\")\n",
                "bedrock_embedding_model_id = os.getenv(\"BEDROCK_EMBEDDING_MODEL_ID\", \"amazon.titan-embed-text-v2:0\")\n",
                "s3_vector_bucket_name = os.getenv(\"S3_VECTOR_BUCKET_NAME\")\n",
                "s3_vector_index_name = os.getenv(\"S3_VECTOR_INDEX_NAME\")\n",
                "\n",
                "print(f\"AWS Region: {aws_region}\")\n",
                "print(f\"AWS Profile: {aws_profile}\")\n",
                "print(f\"Bedrock Embedding Model: {bedrock_embedding_model_id}\")\n",
                "print(f\"S3 Vector Bucket: {s3_vector_bucket_name}\")\n",
                "print(f\"S3 Vector Index: {s3_vector_index_name}\")\n",
                "\n",
                "# Setup AWS Session\n",
                "session = boto3.Session(profile_name=aws_profile, region_name=aws_region)\n",
                "bedrock_client = session.client(\"bedrock-runtime\")\n",
                "\n",
                "# Initialize S3 Vectors Client\n",
                "try:\n",
                "    s3_vectors_client = session.client(\"s3vectors\")\n",
                "    print(\"‚úÖ S3 Vectors client initialized.\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è Failed to initialize 's3vectors' client. Ensure your boto3 version supports it. Error: {e}\")\n",
                "    s3_vectors_client = None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "predefined_text_md",
            "metadata": {},
            "source": [
                "## Step 1: Define Predefined Text Chunks\n",
                "Define the text chunks that will be inserted into the vector index."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "predefined_text_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predefined text chunks to insert\n",
                "predefined_texts = [\n",
                "    \"Dynamic dispatch: In traditional distributed systems, the dynamic dispatch pattern selects and invokes specific services at runtime based on incoming event attributes, such as event type, source, and payload. This is commonly implemented using Amazon EventBridge, which can evaluate and route incoming events to appropriate targets (for example, AWS Lambda functions AWS Step Functions, or Amazon Elastic Container Service tasks).\",\n",
                "    \n",
                "    \"An application emits an event (for example, {\\\"type\\\": \\\"orderCreated\\\", \\\"priority\\\": \\\"high\\\"}). Amazon EventBridge evaluates the event against its routing rules. Based on an event's attributes, the system dynamically dispatches to the following: HighPriorityOrderProcessor (service A), StandardOrderProcessor (service B), UpdateOrderProcessor (service C). This pattern supports loose coupling, domain-based specialization, and runtime extensibility. This allows systems to respond intelligently to changing requirements and event semantics.\",\n",
                "    \n",
                "    \"LLM-based routing: In agentic systems, routing also performs dynamic task delegation - but instead of Amazon EventBridge rules or metadata filters, the LLM classifies and interprets the user's intent through natural language. The result is a flexible, semantic, and adaptive form of dispatching.\",\n",
                "    \n",
                "    \"Agent router: This architecture enables rich intent-based dispatching without predefined schemas or event types, which is ideal for unstructured input and complex queries. A user submits the request 'Can you help me review my contract terms?' The LLM interprets this as a legal document task. The agent routes the task to one or more of the following: Contract review prompt template, Legal reasoning subagent, Document parsing tool.\",\n",
                "    \n",
                "    \"Agent router workflow: A user submits a natural language request through an SDK. An Amazon Bedrock agent uses an LLM to classify the task (for example, legal, technical, or scheduling). The agent dynamically routes the task through an action group to invoke the required agent: Domain-specific agent, Specialized tool chain, Custom prompt configuration. The selected handler processes the task and returns a tailored response.\",\n",
                "    \n",
                "    \"Takeaways: Where traditional dynamic dispatch uses Amazon EventBridge rules for routing based on structured event attributes, agentic routing uses LLMs to semantically classify and route tasks based on meaning and intent. This expands the system's flexibility by enabling: Broader input understanding, Intelligent fallback and tool selection, Natural extensibility through new agent roles or prompt styles. Agentic routing replaces rigid rules with dynamic cognitive dispatching, which allows systems to evolve with language rather than code.\",\n",
                "    \n",
                "    \"Parallelization and scatter-gather patterns: Many advanced reasoning and generation tasks - such as summarizing large documents, evaluating multiple solution paths, or comparing diverse perspectives - benefit from the parallel execution of prompts. Traditional sequential workflows fall short when scalability, responsiveness, and fault tolerance are required. To overcome this, LLM-based parallelization can be reimagined using an event-driven scatter-gather pattern, where tasks are dynamically fanned out to autonomous agents and results intelligently synthesized.\",\n",
                "    \n",
                "    \"Scatter-gather: In distributed systems, a scatter-gather pattern sends tasks to multiple services or processing units in parallel, waits for their responses, and then aggregates results into a consolidated output. Unlike fan-out, scatter-gather is coordinated because it expects responses and usually applies logic to combine, compare, and select results.\",\n",
                "    \n",
                "    \"Common implementations for parallelization and scatter-gather include the following: AWS Step Functions map a state for parallel task execution, AWS Lambda with concurrency, coordinating results from multiple invoked functions, Amazon EventBridge with correlation IDs and aggregation workflows, Custom controller pattern to manage fan-out and gather results by using Amazon Simple Storage Service (Amazon S3), Amazon DynamoDB, or queues.\"\n",
                "]\n",
                "\n",
                "print(f\"‚úÖ Defined {len(predefined_texts)} text chunks for insertion.\")\n",
                "for i, text in enumerate(predefined_texts, 1):\n",
                "    print(f\"{i}. {text[:80]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "embedding_md",
            "metadata": {},
            "source": [
                "## Step 2: Generate Embeddings\n",
                "Use the Titan v2 model to generate embeddings for each text chunk."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "embedding_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_embedding(text, model_id=bedrock_embedding_model_id):\n",
                "    \"\"\"\n",
                "    Generate embedding for a given text using Amazon Bedrock Titan model.\n",
                "    \"\"\"\n",
                "    try:\n",
                "        body = json.dumps({\n",
                "            \"inputText\": text,\n",
                "            # Optional: \"dimensions\": 1024, \"normalize\": True\n",
                "        })\n",
                "        \n",
                "        response = bedrock_client.invoke_model(\n",
                "            body=body,\n",
                "            modelId=model_id,\n",
                "            accept=\"application/json\",\n",
                "            contentType=\"application/json\"\n",
                "        )\n",
                "        \n",
                "        response_body = json.loads(response.get(\"body\").read())\n",
                "        embedding = response_body.get(\"embedding\")\n",
                "        return embedding\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error generating embedding: {e}\")\n",
                "        return None\n",
                "\n",
                "# Test embedding generation\n",
                "test_embedding = get_embedding(predefined_texts[0])\n",
                "if test_embedding:\n",
                "    print(f\"‚úÖ Successfully generated embedding with dimension: {len(test_embedding)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "insert_md",
            "metadata": {},
            "source": [
                "## Step 3: Insert Vectors into S3 Vector Index\n",
                "For each text chunk:\n",
                "1. Generate a unique ID (similar to nanoid)\n",
                "2. Create embedding\n",
                "3. Create metadata with id and chunk\n",
                "4. Insert into the vector index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "insert_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def insert_vector(text, bucket_name, index_name):\n",
                "    \"\"\"\n",
                "    Insert a single text chunk into the S3 Vector Index.\n",
                "    \"\"\"\n",
                "    if not s3_vectors_client:\n",
                "        print(\"‚ùå S3 Vectors client is not initialized.\")\n",
                "        return False\n",
                "    \n",
                "    if not bucket_name or not index_name:\n",
                "        print(\"‚ö†Ô∏è S3_VECTOR_BUCKET_NAME or S3_VECTOR_INDEX_NAME is not set.\")\n",
                "        return False\n",
                "    \n",
                "    # Generate unique ID\n",
                "    unique_id = generate_nanoid()\n",
                "    \n",
                "    # Generate embedding\n",
                "    embedding = get_embedding(text)\n",
                "    if not embedding:\n",
                "        print(f\"‚ùå Failed to generate embedding for text: {text[:50]}...\")\n",
                "        return False\n",
                "    \n",
                "    # Create metadata\n",
                "    metadata = {\n",
                "        \"id\": unique_id,\n",
                "        \"chunk\": text\n",
                "    }\n",
                "    \n",
                "    try:\n",
                "        # Insert vector into S3 Vector Index\n",
                "        response = s3_vectors_client.put_vectors(\n",
                "            vectorBucketName=bucket_name,\n",
                "            indexName=index_name,\n",
                "            vectors=[\n",
                "                {\n",
                "                    \"key\": unique_id,\n",
                "                    \"data\": {\"float32\": embedding},\n",
                "                    \"metadata\": metadata\n",
                "                }\n",
                "            ]\n",
                "        )\n",
                "        \n",
                "        print(f\"‚úÖ Inserted vector with ID: {unique_id}\")\n",
                "        print(f\"   Text preview: {text[:80]}...\")\n",
                "        return True\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error inserting vector: {e}\")\n",
                "        return False\n",
                "\n",
                "# Insert all predefined texts\n",
                "print(\"\\nüöÄ Starting vector insertion...\\n\")\n",
                "success_count = 0\n",
                "fail_count = 0\n",
                "\n",
                "for i, text in enumerate(predefined_texts, 1):\n",
                "    print(f\"\\n[{i}/{len(predefined_texts)}] Processing...\")\n",
                "    if insert_vector(text, s3_vector_bucket_name, s3_vector_index_name):\n",
                "        success_count += 1\n",
                "    else:\n",
                "        fail_count += 1\n",
                "\n",
                "print(f\"\\n\\nüìä Insertion Summary:\")\n",
                "print(f\"   ‚úÖ Successful: {success_count}\")\n",
                "print(f\"   ‚ùå Failed: {fail_count}\")\n",
                "print(f\"   üìù Total: {len(predefined_texts)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "verify_md",
            "metadata": {},
            "source": [
                "## Step 4: Verify Insertion (Optional)\n",
                "Perform a test query to verify that the vectors were inserted successfully."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "verify_code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîç Testing with query: 'Explain how EventBridge works in LLM Workflow context?'\n",
                        "\n",
                        "‚úÖ Found 3 similar vectors:\n",
                        "\n",
                        "1. ID: HlgHN84M1CUmWH3q5tzHl\n",
                        "   Distance: 0.4293\n",
                        "   Text: An application emits an event (for example, {\"type\": \"orderCreated\", \"priority\": \"high\"}). Amazon EventBridge evaluates the event against its routing rules. Based on an event's attributes, the system dynamically dispatches to the following: HighPriorityOrderProcessor (service A), StandardOrderProcessor (service B), UpdateOrderProcessor (service C). This pattern supports loose coupling, domain-based specialization, and runtime extensibility. This allows systems to respond intelligently to changing requirements and event semantics.\n",
                        "\n",
                        "2. ID: Pv2Y1r0zYKxdFRrToZ0fo\n",
                        "   Distance: 0.5672\n",
                        "   Text: LLM-based routing: In agentic systems, routing also performs dynamic task delegation - but instead of Amazon EventBridge rules or metadata filters, the LLM classifies and interprets the user's intent through natural language. The result is a flexible, semantic, and adaptive form of dispatching.\n",
                        "\n",
                        "3. ID: Cp98hjhcis6SSNooIuhZ8\n",
                        "   Distance: 0.6386\n",
                        "   Text: Agent router workflow: A user submits a natural language request through an SDK. An Amazon Bedrock agent uses an LLM to classify the task (for example, legal, technical, or scheduling). The agent dynamically routes the task through an action group to invoke the required agent: Domain-specific agent, Specialized tool chain, Custom prompt configuration. The selected handler processes the task and returns a tailored response.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Test query to verify insertion\n",
                "test_query = \"Explain how EventBridge works in LLM Workflow context?\"\n",
                "print(f\"üîç Testing with query: '{test_query}'\\n\")\n",
                "\n",
                "# Generate embedding for test query\n",
                "query_embedding = get_embedding(test_query)\n",
                "\n",
                "if query_embedding and s3_vectors_client:\n",
                "    try:\n",
                "        response = s3_vectors_client.query_vectors(\n",
                "            vectorBucketName=s3_vector_bucket_name,\n",
                "            indexName=s3_vector_index_name,\n",
                "            queryVector={\"float32\": query_embedding},\n",
                "            topK=3,\n",
                "            returnDistance=True,\n",
                "            returnMetadata=True\n",
                "        )\n",
                "        \n",
                "        vectors = response.get('vectors', [])\n",
                "        print(f\"‚úÖ Found {len(vectors)} similar vectors:\\n\")\n",
                "        \n",
                "        for i, result in enumerate(vectors, 1):\n",
                "            metadata = result.get('metadata', {})\n",
                "            chunk_text = metadata.get('chunk', '')\n",
                "            vector_id = metadata.get('id', '')\n",
                "            distance = result.get('distance', 0)\n",
                "            \n",
                "            print(f\"{i}. ID: {vector_id}\")\n",
                "            print(f\"   Distance: {distance:.4f}\")\n",
                "            print(f\"   Text: {chunk_text}\")\n",
                "            print()\n",
                "            \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error querying vectors: {e}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Skipping verification - client not initialized or embedding failed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
